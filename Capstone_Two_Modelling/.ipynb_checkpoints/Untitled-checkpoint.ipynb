{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bdb6272",
   "metadata": {},
   "source": [
    "### ***Modeling Durham County Inspection Grades ***\n",
    "\n",
    "Notebook by Temilola Famakinwa\n",
    "\n",
    "\n",
    "**Overview**\n",
    "\n",
    "In the last notebook inspection data was processed to create training and test data from Durham county inspection data, and stored as csv files. \n",
    "\n",
    "In this notebook we will model the data using:\n",
    "  * Linear Regression\n",
    "  * K-Nearest Neighbor (KNN)\n",
    "  * Support Vector Machine (SVM)\n",
    "  * RanfomForest\n",
    "  * XGBoost\n",
    "The best model will be found by using cross validation will be used  to evaluate model accuracy and select the best one. Finally, hyperparameter tuning will be used on the best model using Random Search and Bayes Optimization to determine best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7c298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/24/ec/ad387100fa3cc2b9b81af0829b5ecfe75ec5bb19dd7c19d4fea06fb81802/xgboost-2.0.3-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\fabby\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\fabby\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB 325.1 kB/s eta 0:05:07\n",
      "   ---------------------------------------- 0.1/99.8 MB 544.7 kB/s eta 0:03:04\n",
      "   ---------------------------------------- 0.2/99.8 MB 1.2 MB/s eta 0:01:26\n",
      "   ---------------------------------------- 0.4/99.8 MB 2.0 MB/s eta 0:00:50\n",
      "   ---------------------------------------- 0.7/99.8 MB 2.8 MB/s eta 0:00:36\n",
      "    --------------------------------------- 1.3/99.8 MB 4.6 MB/s eta 0:00:22\n",
      "    --------------------------------------- 1.3/99.8 MB 4.6 MB/s eta 0:00:22\n",
      "    --------------------------------------- 2.0/99.8 MB 5.2 MB/s eta 0:00:19\n",
      "    --------------------------------------- 2.4/99.8 MB 5.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 3.2/99.8 MB 6.7 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 4.2/99.8 MB 8.1 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 5.1/99.8 MB 9.1 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 6.0/99.8 MB 9.9 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 7.1/99.8 MB 10.8 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 8.2/99.8 MB 11.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 9.4/99.8 MB 12.5 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.7/99.8 MB 17.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 10.9/99.8 MB 17.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 11.8/99.8 MB 19.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 13.4/99.8 MB 21.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 14.8/99.8 MB 23.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 16.0/99.8 MB 23.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 17.4/99.8 MB 26.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 18.1/99.8 MB 23.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 19.5/99.8 MB 24.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 20.4/99.8 MB 25.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 21.9/99.8 MB 27.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 23.1/99.8 MB 27.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 23.7/99.8 MB 26.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 24.6/99.8 MB 23.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 25.5/99.8 MB 22.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 26.2/99.8 MB 21.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 27.0/99.8 MB 21.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 28.1/99.8 MB 21.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 28.9/99.8 MB 21.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 20.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 30.4/99.8 MB 18.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 31.4/99.8 MB 19.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 31.6/99.8 MB 18.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 32.4/99.8 MB 17.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 32.9/99.8 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 33.9/99.8 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 34.8/99.8 MB 16.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 36.0/99.8 MB 17.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 37.0/99.8 MB 18.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 37.6/99.8 MB 17.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 38.5/99.8 MB 17.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 39.6/99.8 MB 18.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 40.7/99.8 MB 18.7 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 41.6/99.8 MB 18.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 42.4/99.8 MB 19.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 43.3/99.8 MB 20.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 44.5/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 45.4/99.8 MB 20.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 46.6/99.8 MB 21.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 47.5/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 48.5/99.8 MB 21.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 49.5/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 50.6/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 51.3/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 52.3/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 53.2/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 54.2/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 54.8/99.8 MB 21.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 55.6/99.8 MB 19.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 56.2/99.8 MB 19.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 57.1/99.8 MB 18.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 57.9/99.8 MB 18.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 58.7/99.8 MB 18.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 59.9/99.8 MB 18.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 61.1/99.8 MB 19.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 61.9/99.8 MB 19.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 62.9/99.8 MB 19.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 63.9/99.8 MB 19.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 64.9/99.8 MB 19.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 65.8/99.8 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 66.8/99.8 MB 21.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 68.0/99.8 MB 21.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 69.1/99.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 70.3/99.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 71.6/99.8 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 72.6/99.8 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 73.6/99.8 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 74.6/99.8 MB 24.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 75.7/99.8 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 77.0/99.8 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 78.1/99.8 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 79.3/99.8 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 79.8/99.8 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 81.0/99.8 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 82.0/99.8 MB 22.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 82.6/99.8 MB 21.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 83.4/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 83.9/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 85.5/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 87.5/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 88.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.1/99.8 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.3/99.8 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.3/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.3/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.4/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 94.4/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 95.4/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.7/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.7/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.6/99.8 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/99.8 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 11.3 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32c28c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import modeling tools\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Import data analysis modules\n",
    "import pandas as pd\n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "def6623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('y_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_test = pd.read_csv('Xtest_scaled.csv')\n",
    "X_train = pd.read_csv('Xtrain_scaled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21135e5d",
   "metadata": {},
   "source": [
    "### **Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06d5b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  score_sum\n",
      "0        7448        0.0\n",
      "1        3896       94.0\n",
      "   Unnamed: 0  score_sum\n",
      "0        1215      100.0\n",
      "1         728        8.0\n",
      "   Unnamed: 0         0         1         2         3         4         5  \\\n",
      "0           0  1.484854  1.482477 -0.739203 -0.148884 -0.119389  0.454282   \n",
      "1           1 -0.668479 -0.674189  1.127149 -0.712652  1.202334  0.744185   \n",
      "\n",
      "          6         7         8  ...      222       223       224       225  \\\n",
      "0  3.120858 -0.265396  1.870302  ... -0.13803 -0.155735 -0.104262 -0.156081   \n",
      "1 -0.453834 -0.265396 -0.173483  ... -0.13803 -0.155735 -0.104262 -0.156081   \n",
      "\n",
      "        226       227       228       229       230       231  \n",
      "0 -0.118751 -0.349072 -0.112773 -0.131879 -0.134282 -0.121716  \n",
      "1 -0.118751 -0.349072 -0.112773 -0.131879 -0.134282 -0.121716  \n",
      "\n",
      "[2 rows x 233 columns]\n",
      "   Unnamed: 0         0         1         2         3         4         5  \\\n",
      "0           0 -0.668479 -0.674189  1.127149  2.362975  1.202334  0.743246   \n",
      "1           1  1.484854  1.482477 -1.101162 -0.245382 -0.479859 -1.609843   \n",
      "\n",
      "          6         7         8  ...      222       223       224       225  \\\n",
      "0 -0.367791  0.252919  1.461545  ... -0.13803 -0.155735 -0.104262 -0.156081   \n",
      "1 -0.125307 -0.265396 -0.990997  ... -0.13803 -0.155735 -0.104262 -0.156081   \n",
      "\n",
      "        226       227       228       229       230       231  \n",
      "0 -0.118751 -0.349072 -0.112773 -0.131879 -0.134282 -0.121716  \n",
      "1 -0.118751 -0.349072 -0.112773 -0.131879 -0.134282 -0.121716  \n",
      "\n",
      "[2 rows x 233 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.head(2))\n",
    "print(y_train.head(2))\n",
    "print(X_train.head(2))\n",
    "print(X_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c04924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Unnnamed: 0 column from every dataframe.\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis = 1)\n",
    "y_test = y_test.drop(['Unnamed: 0'], axis = 1)\n",
    "X_train = X_train.drop(['Unnamed: 0'], axis = 1)\n",
    "X_test = X_test.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e78f3615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   score_sum\n",
      "0        0.0\n",
      "1       94.0\n",
      "   score_sum\n",
      "0      100.0\n",
      "1        8.0\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  1.484854  1.482477 -0.739203 -0.148884 -0.119389  0.454282  3.120858   \n",
      "1 -0.668479 -0.674189  1.127149 -0.712652  1.202334  0.744185 -0.453834   \n",
      "\n",
      "          7         8         9  ...      222       223       224       225  \\\n",
      "0 -0.265396  1.870302  1.618212  ... -0.13803 -0.155735 -0.104262 -0.156081   \n",
      "1 -0.265396 -0.173483 -0.755277  ... -0.13803 -0.155735 -0.104262 -0.156081   \n",
      "\n",
      "        226       227       228       229       230       231  \n",
      "0 -0.118751 -0.349072 -0.112773 -0.131879 -0.134282 -0.121716  \n",
      "1 -0.118751 -0.349072 -0.112773 -0.131879 -0.134282 -0.121716  \n",
      "\n",
      "[2 rows x 232 columns]\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0 -0.668479 -0.674189  1.127149  2.362975  1.202334  0.743246 -0.367791   \n",
      "1  1.484854  1.482477 -1.101162 -0.245382 -0.479859 -1.609843 -0.125307   \n",
      "\n",
      "          7         8         9  ...      222       223       224       225  \\\n",
      "0  0.252919  1.461545  0.940073  ... -0.13803 -0.155735 -0.104262 -0.156081   \n",
      "1 -0.265396 -0.990997  0.261933  ... -0.13803 -0.155735 -0.104262 -0.156081   \n",
      "\n",
      "        226       227       228       229       230       231  \n",
      "0 -0.118751 -0.349072 -0.112773 -0.131879 -0.134282 -0.121716  \n",
      "1 -0.118751 -0.349072 -0.112773 -0.131879 -0.134282 -0.121716  \n",
      "\n",
      "[2 rows x 232 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.head(2))\n",
    "print(y_train.head(2))\n",
    "print(X_train.head(2))\n",
    "print(X_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22ffa615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer(estimator, *args, **routed_params.get(name).score)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 759, in score\n",
      "    y_pred = self.predict(X)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 386, in predict\n",
      "    return self._decision_function(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 369, in _decision_function\n",
      "    X = self._validate_data(X, accept_sparse=[\"csr\", \"csc\", \"coo\"], reset=False)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 604, in _validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 678, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Score</th>\n",
       "      <th>Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CV_Score  Folds\n",
       "0       NaN      1\n",
       "1       NaN      2\n",
       "2       NaN      3\n",
       "3       NaN      4\n",
       "4       NaN      5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create set cross validation folds\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n",
    "\n",
    "# Instantiate linear regression object\n",
    "reg = LinearRegression()\n",
    "\n",
    "cv_results = cross_val_score(reg, X_train, y_train, cv = kf)\n",
    "cv_results_reg = pd.DataFrame(cv_results, columns =['CV_Score'])\n",
    "cv_results_reg['Folds'] = [1,2,3,4,5]\n",
    "cv_results_reg\n",
    "    \n",
    "#reg.fit(X_train, y_train)\n",
    "#predictions = reg.predict(X_train)\n",
    "#plt.plot(X_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d8a9451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of CV score for linear regression: nan\n",
      "Standard deviation of  CV score for linear regression: nan\n"
     ]
    }
   ],
   "source": [
    "reg_cv_avg = np.mean(cv_results)\n",
    "reg_cv_std = np.std(cv_results)\n",
    "print('Mean of CV score for linear regression: ' + str(reg_cv_avg))\n",
    "print('Standard deviation of  CV score for linear regression: ' + str(reg_cv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d419d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer(estimator, *args, **routed_params.get(name).score)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 228, in fit\n",
      "    return self._fit(X, y)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 456, in _fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\fabby\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Score</th>\n",
       "      <th>Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CV_Score  Folds\n",
       "0       NaN      1\n",
       "1       NaN      2\n",
       "2       NaN      3\n",
       "3       NaN      4\n",
       "4       NaN      5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=len(X_train))\n",
    "cv_results = cross_val_score(knn, X_train, y_train, cv = kf)\n",
    "cv_results_knn = pd.DataFrame(cv_results, columns =['CV_Score'])\n",
    "cv_results_knn['Folds'] = [1,2,3,4,5]\n",
    "cv_results_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2076fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of CV score for KNN: nan\n",
      "Standard deviation of  CV score for KNN: nan\n"
     ]
    }
   ],
   "source": [
    "knn_cv_avg = np.mean(cv_results)\n",
    "knn_cv_std = np.std(cv_results)\n",
    "print('Mean of CV score for KNN: ' + str(knn_cv_avg))\n",
    "print('Standard deviation of  CV score for KNN: ' + str(knn_cv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f58dc13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "227    0\n",
       "228    0\n",
       "229    0\n",
       "230    0\n",
       "231    0\n",
       "Length: 232, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d950b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
